---
title: "Complementary Log-Log Ordinal BART in StochTree"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{CLogLog-Ordinal-BART}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
bibliography: vignettes.bib
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette demonstrates how to use the `cloglog_ordinal_bart()` function for modeling ordinal outcomes using a complementary log-log link function in the BART (Bayesian Additive Regression Trees) framework. 

To begin, we load the `stochtree` package.

```{r setup}
library(stochtree)
```

# Introduction to Ordinal BART with CLogLog Link

Ordinal data represents outcomes that have a natural ordering but undefined distances between categories. Examples include survey responses (strongly disagree, disagree, neutral, agree, strongly agree), severity ratings (mild, moderate, severe), or educational levels (elementary, high school, college, graduate).

The complementary log-log (CLogLog) model uses the link function:
$$\text{cloglog}(p) = \log(-\log(1-p))$$

This link function is asymmetric and particularly appropriate when the probability of being in higher categories changes rapidly at certain thresholds, making it different from the symmetric probit or logit links commonly used in ordinal regression.

In the BART framework with CLogLog ordinal regression, we model:
$$P(Y = k \mid Y \geq k, X = x) = 1 - \exp\left(-e^{\gamma_k + \lambda(x)}\right)$$

where $\lambda(x)$ is learned by the BART ensemble and $c_k = \log \sum_{j \leq k}e^{\gamma_j}$ are the cutpoints for the ordinal categories.

## Data Simulation

```{r demo1-simulation}
set.seed(2025)
# Sample size and number of predictors
n <- 2000
p <- 5

# Design matrix and true lambda function
X <- matrix(rnorm(n * p), n, p)
beta <- rep(1 / sqrt(p), p)
true_lambda_function <- X %*% beta


# Set cutpoints for ordinal categories (3 categories: 1, 2, 3)
n_categories <- 3
gamma_true <- c(-2, 1)
ordinal_cutpoints <- log(cumsum(exp(gamma_true)))
ordinal_cutpoints

# True ordinal class probabilities
true_probs <- matrix(0, nrow = n, ncol = n_categories)
for (j in 1:n_categories) {
  if (j == 1) {
    true_probs[, j] <- 1 - exp(-exp(gamma_true[j] + true_lambda_function))
  } else if (j == n_categories) {
    true_probs[, j] <- 1 - rowSums(true_probs[, 1:(j - 1), drop = FALSE])
  } else {
    true_probs[, j] <- exp(-exp(gamma_true[j - 1] + true_lambda_function)) *
      (1 - exp(-exp(gamma_true[j] + true_lambda_function)))
  }
}

# Generate ordinal outcomes
y <- sapply(1:nrow(X), function(i) sample(1:n_categories, 1, prob = true_probs[i, ]))
cat("Outcome distribution:", table(y), "\n")
```

## Model Fitting

Now let's fit the CLogLog Ordinal BART model:

```{r demo1-model-fitting}
# Split data into train and test sets
train_idx <- sample(1:n, size = floor(0.8 * n))
test_idx <- setdiff(1:n, train_idx)

X_train <- X[train_idx, ]
y_train <- y[train_idx]
X_test <- X[test_idx, ]
y_test <- y[test_idx]

# Fit CLogLog Ordinal BART model
out <- stochtree::cloglog_ordinal_bart(
  X = X_train,
  y = y_train,
  X_test = X_test,
  n_samples_mcmc = 1000,
  n_burnin = 500,
  n_thin = 1
)
```

## Model Results and Interpretation

Let's examine the posterior samples and model performance:

```{r demo1-results}
# Compare forest predictions with the truth function (for training and test sets)
lambda_pred_train <- rowMeans(out$forest_predictions_train) - mean(out$forest_predictions_train)
plot(lambda_pred_train, true_lambda_function[train_idx])
abline(a=0,b=1,col='blue', lwd=2)
cor_train <- cor(true_lambda_function[train_idx], lambda_pred_train)
text(min(true_lambda_function[train_idx]), max(true_lambda_function[train_idx]), paste('Correlation:', round(cor_train, 3)), adj = 0, col = 'red')

lambda_pred_test <- rowMeans(out$forest_predictions_test) - mean(out$forest_predictions_test)
plot(lambda_pred_test, true_lambda_function[test_idx])
abline(a=0,b=1,col='blue', lwd=2)
cor_test <- cor(true_lambda_function[test_idx], lambda_pred_test)
text(min(true_lambda_function[test_idx]), max(true_lambda_function[test_idx]), paste('Correlation:', round(cor_test, 3)), adj = 0, col = 'red')

# Estimated ordinal class probabilities for the training set
est_probs_train <- matrix(0, nrow=length(train_idx), ncol=n_categories)
for (j in 1:n_categories) {
  if (j == 1) {
    est_probs_train[, j] <- rowMeans(1 - exp(-exp(out$forest_predictions_train + out$gamma_samples[j, ])))
  } else if (j == n_categories) {
    est_probs_train[, j] <- 1 - rowSums(est_probs_train[, 1:(j - 1), drop = FALSE])
  } else {
    est_probs_train[, j] <- rowMeans(exp(-exp(out$forest_predictions_train + out$gamma_samples[j-1,])) *
                                       (1 - exp(-exp(out$forest_predictions_train + out$gamma_samples[j,]))))
  }
}

# Compare estimated vs true class probabilities for training set
for (j in 1:n_categories) {
  plot(true_probs[train_idx, j], est_probs_train[, j], xlab = paste("True Prob Category", j), ylab = paste("Estimated Prob Category", j))
  abline(a = 0, b = 1, col = 'blue', lwd = 2)
  cor_train_prob <- cor(true_probs[train_idx, j], est_probs_train[, j])
  text(min(true_probs[train_idx, j]), max(est_probs_train[, j]), paste('Correlation:', round(cor_train_prob, 3)), adj = 0, col = 'red')
}

# Estimated ordinal class probabilities for the test set
est_probs_test <- matrix(0, nrow=length(test_idx), ncol=n_categories)
for (j in 1:n_categories) {
  if (j == 1) {
    est_probs_test[, j] <- rowMeans(1 - exp(-exp(out$forest_predictions_test + out$gamma_samples[j, ])))
  } else if (j == n_categories) {
    est_probs_test[, j] <- 1 - rowSums(est_probs_test[, 1:(j - 1), drop = FALSE])
  } else {
    est_probs_test[, j] <- rowMeans(exp(-exp(out$forest_predictions_test + out$gamma_samples[j-1,])) *
                                       (1 - exp(-exp(out$forest_predictions_test + out$gamma_samples[j,]))))
  }
}

# Compare estimated vs true class probabilities for test set
for (j in 1:n_categories) {
  plot(true_probs[test_idx, j], est_probs_test[, j], xlab = paste("True Prob Category", j), ylab = paste("Estimated Prob Category", j))
  abline(a = 0, b = 1, col = 'blue', lwd = 2)
  cor_test_prob <- cor(true_probs[test_idx, j], est_probs_test[, j])
  text(min(true_probs[test_idx, j]), max(est_probs_test[, j]), paste('Correlation:', round(cor_test_prob, 3)), adj = 0, col = 'red')
}
```

# Conclusion

The CLogLog Ordinal BART model in `stochtree` provides a flexible and powerful approach for modeling ordinal outcomes, especially better suited for asymmetric outcomes: Rare events (e.g., credit default, fraud detection, system failures, adverse drug reactions), Toxic thresholds (e.g., credit risk escalation, dose-response toxicity, engagement drop-offs), Discrete survival outcomes (e.g., time-to-default, customer churn, progression-free survival).

The CLogLog Ordinal BART implementation in `stochtree` builds on the paper by @alam2025unified.

# References
